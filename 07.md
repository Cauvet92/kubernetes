# Déploiement de microservices stateful : persistance de données dans Kubernetes

## Prérequis

Nous utilisons toujours le même serveur de développement Ubuntu 22.04. Nous l'utilisons pour créer et déployer des ressources Kubernetes.

Dans cette partie du guide, nous allons déployer une base de données PostgreSQL et modifier le code de notre application Flask pour qu'elle utilise la base de données pour stocker son état. Lorsqu'un utilisateur ajoute un élément à la liste de tâches à effectuer, il ne disparaîtra pas lorsque le pod redémarrera ou disparaîtra, car tout sera enregistré dans la base de données PostgreSQL. Cela ne rendra pas notre microservice stateful, mais un microservice stateless qui stocke son état sur une base de données externe.

Assurez-vous d'avoir déjà installé virtualenvwrapper:

```bash
apt update &&  apt install -y python3-pip

pip install virtualenvwrapper
export WORKON_HOME=~/Envs
mkdir -p $WORKON_HOME
export VIRTUALENVWRAPPER_PYTHON='/usr/bin/python3'
source /usr/local/bin/virtualenvwrapper.sh
```

Ensuite, activez l'environnement virtuel:

```bash
mkvirtualenv stateful-flask
```

Maintenant, créez un dossier pour la nouvelle application:

```bash
cd $HOME
mkdir -p stateful-flask
cd stateful-flask
mkdir -p app
mkdir -p kubernetes
```

Nous allons utiliser `stateful-flask` comme nom au lieu de `stateless-flask` dans la partie précédente. Cependant, comme indiqué, cela ne signifie pas que la nouvelle application Flask que nous allons créer est stateful, elle est toujours stateless mais utilise un datastore externe (PostgreSQL) pour stocker son état. La base de données, en revanche, est un service stateful.

## Créer un namespace

Commençons par créer un namespace pour la base de données :

```yaml
cat <<EOF > kubernetes/postgres-namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: postgres
EOF
```

Et un namespace pour l'application Flask :

```yaml
cat <<EOF > kubernetes/namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: stateful-flask
EOF
```

Ensuite, nous appliquons les namespaces:

```bash
kubectl apply -f kubernetes/postgres-namespace.yaml
kubectl apply -f kubernetes/namespace.yaml
```

## Créer un ConfigMap pour la base de données PostgreSQL

### Qu'est-ce qu'un ConfigMap ?

Un ConfigMap est une ressource qui stocke des données de configuration non confidentielles sous forme de paires clé-valeur. Il permet de découpler les données de configuration des applications conteneurisées, ce qui facilite la mise à jour et la gestion des configurations sans avoir à reconstruire et redéployer l'application entière.

Les ConfigMaps peuvent stocker des données de configuration telles que des variables d'environnement, des fichiers de configuration et toutes autres données non confidentielles nécessaires à vos applications. Lorsqu'un Pod démarre, il peut lire les données de configuration d'un conteneur à partir de la ConfigMap en tant que variables d'environnement ou de fichiers montés dans un volume.

Cette ressource est particulièrement utile dans plusieurs scénarios, notamment lorsque plusieurs applications partagent la même configuration, lorsque les données de configuration doivent être modifiées fréquemment sans redéployer les Pods ou lorsque vous voulez organiser vos déploiements en séparant les opérations des données. Au lieu de gérer la configuration pour chaque application séparément, une seule ConfigMap peut être utilisée pour stocker les données de configuration, qui peuvent ensuite être accessibles par plusieurs applications.

Les ConfigMaps peuvent être créées à l'aide de l'outil en ligne de commande `kubectl` ou en déclarant un objet ConfigMap dans un fichier de manifeste.

### ConfigMap pour PostgreSQL

Dans les étapes suivantes, nous allons créer une ConfigMap pour PostgreSQL. La ConfigMap contiendra les fichiers suivants :

- `POSTGRES_DB` - le nom de la base de données à créer
- `POSTGRES_USER` - le nom de l'utilisateur à créer
- `POSTGRES_PASSWORD` - le mot de passe de l'utilisateur à créer

```yaml
cat <<EOF > kubernetes/postgres-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: postgres
  labels:
    app: postgres
data:
  POSTGRES_DB: stateful-flask-db
  POSTGRES_USER: stateful-flask-user
  POSTGRES_PASSWORD: stateful-flask-password
EOF
```

Appliquez la ConfigMap :

```bash
kubectl apply -f kubernetes/postgres-config.yaml
```

## Persisting data storage on PostgreSQL

### Volumes Kubernetes

Un volume est une couche d'abstraction entre le conteneur et le stockage physique. Il permet aux conteneurs de stocker et d'accéder aux données indépendamment de l'infrastructure sous-jacente (AWS, GCP, Azure, etc.).

Les volumes fournissent un moyen de stocker et de persister des données dans un conteneur au-delà de la durée de vie d'un Pod et permettent le partage de données entre les Pods.

Les volumes Kubernetes peuvent être créés à partir de différentes sources telles qu'un disque local, un système de fichiers réseau ou un bloc de stockage d'un fournisseur de cloud. Ils peuvent être montés dans un conteneur en tant que répertoire ou fichier et être accessibles et manipulés comme n'importe quel autre système de fichiers.

### Demandes d'espaces de stockage (VolumeClaims)

Un volume claim est la requête d'un utilisateur pour du stockage. Elle spécifie la quantité d'espace de stockage qu'un Pod devrait avoir à sa disposition et utilise une classe de stockage pour définir comment le stockage doit être provisionné.

### Classe de stockage (StorageClass)

La classe de stockage est un objet qui définit le type de stockage à utiliser pour le provisioning dynamique d'un volume persistant (PV) en réponse à une demande de volume persistant (PVC) faite par un Pod et configurée par un utilisateur.

Quelques exemples de classe de stockage dans Kubernetes sont:

- aws-ebs : une classe de stockage pour les volumes Amazon Elastic Block Store (EBS).
- azure-disk : une classe de stockage pour les disques Azure.
- csi-cephfs : une classe de stockage pour les volumes CephFS utilisant le pilote Container Storage Interface (CSI).
- do-block-storage : une forme de stockage persistant offerte par DigitalOcean (DO) qui fournit des volumes de stockage basés sur SSD pour stocker des données.
- local-storage : une classe de stockage pour le stockage local sur un nœud.

### Ajout de stockage à PostgreSQL

Pour ajouter du stockage à PostgreSQL, vous devez créer un `PersistentVolumeClaim` et un `PersistentVolume`.

```yaml
cat <<EOF > kubernetes/postgres-pvc-pv.yaml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: postgres-pv-claim
  namespace: postgres
  labels:
    app: postgres
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
  storageClassName: do-block-storage
EOF
```

Explications:

- `PersistentVolumeClaim` :
  - Le PVC est défini avec **`kind`** réglé sur **`PersistentVolumeClaim`** et **`metadata`** définissant le **`name`**, **`namespace`**, et **`labels`**.
  - Les **`accessModes`** sont réglés sur **`ReadWriteOnce`**, ce qui signifie que le volume peut être lu et écrit par un seul noeud à la fois.
  - Les **`resources`** définissent la quantité de stockage demandée pour le PVC.
  - Enfin, **`storageClassName`** est réglé sur **`do-block-storage`**, qui correspond à la classe de stockage utilisée par le PV.

Il y a différents modes d'accès pour les `PersistentVolumes` et les `PersistentVolumeClaims`, comme cela est indiqué dans la documentation officielle :

- **`ReadWriteOnce` :** Le volume peut être monté en lecture-écriture par un seul nœud. Le mode d'accès `ReadWriteOnce` peut encore permettre à plusieurs pods d'accéder au volume quand les pods sont en cours d'exécution sur le même nœud.
- **`ReadOnlyMany` :** Le volume peut être monté en lecture seule par plusieurs nœuds.
- **`ReadWriteMany` :** Le volume peut être monté en lecture-écriture par plusieurs nœuds.
- **`ReadWriteOncePod` :** Le volume peut être monté en lecture-écriture par un seul pod. Utilisez le mode d'accès `ReadWriteOncePod` si vous voulez vous assurer qu'un seul pod dans l'ensemble du cluster peut lire ce volume ou y écrire. Ce mode est uniquement pris en charge pour les [volumes CSI](https://kubernetes.io/blog/2019/01/15/container-storage-interface-ga/) et pour les versions de Kubernetes 1.22 ou supérieures.

Créons le `PersistentVolume` et `PersistentVolumeClaim` :

```bash
kubectl apply -f kubernetes/postgres-pvc-pv.yaml
```

Vous pouvez vérifier l'état du `PersistentVolume` et du `PersistentVolumeClaim` à l'aide des commandes suivantes :

```bash
kubectl get pv
kubectl get pvc -n postgres
```

### Création d'un déploiement pour PostgreSQL

Nous allons utiliser la commande suivante pour créer un déploiement pour PostgreSQL.

Bien que ce ne soit pas la meilleure ressource à utiliser avec PostgreSQL, nous utiliserons le déploiement pour l'instant.

```yaml
cat <<EOF > kubernetes/postgres-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres
  namespace: postgres
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
        - name: postgres
          image: postgres:10.1
          imagePullPolicy: Always
          ports:
            - containerPort: 5432
          envFrom:
            - configMapRef:
                name: postgres-config
          volumeMounts:
            - mountPath: /var/lib/postgresql/data
              subPath: postgres
              name: postgredb
      volumes:
        - name: postgredb
          persistentVolumeClaim:
            claimName: postgres-pv-claim
EOF
```

- Le champs **`spec`** définit l'état désiré du déploiement.
- **`Replicas`** spécifie le nombre de replicas que nous voulons créer.
- **`Selector`** spécifie comment sélectionner les Pods que le déploiement doit gérer. Dans ce cas, le sélecteur correspond aux Pods avec le label **`app: postgres`**.
- Le champs **`template`** spécifie le modèle de Pod utilisé pour créer de nouveaux Pods dans le déploiement.
- **`metadata`** contient des labels qui identifient le Pod comme étant membre du groupe **`app: postgres`**.
- Le champs **`spec`** contient la configuration de conteneur.
- Le conteneur exécute une image PostgreSQL version 10.1 et expose le port 5432 pour la communication.
- **`envFrom`** définit une variable d'environnement provenant d'une ressource de MapConfig nommée **`postgres-config`**.
- Le conteneur nécessite un volume pour le stockage persistant, défini dans le champs **`volumes`**.
- Le volume est nommé **`postgredb`** et est pris en charge par une `PersistentVolumeClaim` (PVC) nommée **`postgres-pv-claim`**.
- Le champs **`volumeMounts`** dans la configuration de conteneur spécifie le volume et son chemin de montage.
- Dans ce cas, le chemin de montage est **`/var/lib/postgresql/data`** et le sous-chemin est **`postgres`**, ce qui signifie que les données de la base de données PostgreSQL sont stockées dans le répertoire **`postgres`** du volume.

Appliquer le déploiement :

```bash
kubectl apply -f kubernetes/postgres-deployment.yaml
```

### Créer un service pour PostgreSQL

Dans cette section, nous allons créer un service pour PostgreSQL. Pour ce faire, nous utiliserons le fichier YAML suivant :

```yaml
cat <<EOF > kubernetes/postgres-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgres # Sets service name
  namespace: postgres
  labels:
    app: postgres # Labels and Selectors
spec:
  type: NodePort # Sets service type
  ports:
    - port: 5432 # Sets port to run the postgres application
  selector:
    app: postgres
EOF
```

Ensuite, nous allons créer le service :

```bash
kubectl apply -f kubernetes/postgres-service.yaml
```

### Création du déploiement pour notre application

Nous allons modifier le code de l'application de manière à la connecter à la base de données PostgreSQL et à stocker chaque élément todo dans la base de données. Pour ce faire, nous utiliserons le fichier YAML suivant :

Assurez-vous que le nouvel environnement virtuel est activé:

```bash
workon stateful-flask
# ou mkvirtualenv stateful-flask
```

Ensuite, installez les dépendances requises:

```bash
pip install Flask==3.0.0
pip install Flask-SQLAlchemy==3.0.3
pip install psycopg2-binary==2.9.6
pip install Flask-Migrate==4.0.4
```

Geler les dépendances:

```bash
pip freeze > app/requirements.txt
```

Maintenant, nous allons changer le code de l'application. Nous ajouterons le code suivant au fichier `app.py`:

```python
cat <<EOF > app/app.py
from flask import Flask, jsonify, request
from flask_sqlalchemy import SQLAlchemy
from flask_migrate import Migrate

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = 'postgresql://stateful-flask-user:stateful-flask-password@postgres.postgres.svc.cluster.local:5432/stateful-flask-db'
db = SQLAlchemy(app)
migrate = Migrate(app, db)

class Task(db.Model):
    id = db.Column(db.Integer, primary_key=True)
    title = db.Column(db.String(80), nullable=False)
    description = db.Column(db.String(200))

@app.route('/tasks', methods=['GET'])
def get_tasks():
    tasks = Task.query.all()
    return jsonify({'tasks': [{'id': task.id, 'title': task.title, 'description': task.description} for task in tasks]})

@app.route('/tasks', methods=['POST'])
def create_task():
    data = request.get_json()
    title = data['title']
    description = data['description']
    task = Task(title=title, description=description)
    db.session.add(task)
    db.session.commit()
    return jsonify({'task': {'id': task.id, 'title': task.title, 'description': task.description}})

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
EOF
```

Nous avons également besoin de ce Dockerfile pour construire l'image:

```Dockerfile
cat <<EOF > app/Dockerfile
FROM python:3.9-slim-buster
WORKDIR /app
COPY . /app
RUN pip install --no-cache-dir -r requirements.txt
EXPOSE 5000
CMD ["python", "app.py"]
EOF
```

Construisez l'image:

```bash
docker build  -t stateful-flask:v0 -f app/Dockerfile app
```

Exécutez le conteneur pour tester l'application :

```bash
docker run -it -p 5000:5000 stateful-flask:v0
```

Vous devriez voir une erreur de connexion à la base de données, ce qui est normal car nous n'avons pas encore déployé l'application sur le cluster, c'est juste un test local.

Nous pouvons renommer et push l'image de l'application sur Docker Hub :

```bash
docker login
# change <dockerhub_username> to your Docker Hub username
export DOCKERHUB_USERNAME=<dockerhub_username>
docker tag stateful-flask:v0 $DOCKERHUB_USERNAME/stateful-flask:v0
docker push $DOCKERHUB_USERNAME/stateful-flask:v0
```

Créons le Déploiement :

```yaml
cat <<EOF > kubernetes/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: stateful-flask
  namespace: stateful-flask
spec:
  replicas: 1
  selector:
    matchLabels:
      app: stateful-flask
  template:
    metadata:
      labels:
        app: stateful-flask
    spec:
      containers:
      - name: stateful-flask
        image: eon01/stateful-flask:v0
        ports:
        - containerPort: 5000
        imagePullPolicy: Always
EOF
```

J'utilise l'image `eon01/stateful-flask:v0`, qui est l'image que j'ai poussée sur Docker Hub. Vous pouvez utiliser votre propre image.

Alors nous allons créer le déploiement:

```bash
kubectl apply -f kubernetes/deployment.yaml
```

Nous pouvons vérifier l'état du déploiement:

```bash
kubectl get pods -n stateful-flask
```

Enfin, nous devons migrer la base de données:

```bash
export pod=$(kubectl get pods -n stateful-flask -l app=stateful-flask -o jsonpath='{.items[0].metadata.name}')
kubectl exec -it $pod -n stateful-flask -- flask db init
kubectl exec -it $pod -n stateful-flask -- flask db migrate
kubectl exec -it $pod -n stateful-flask -- flask db upgrade
```

### Création d'un service pour notre application

Nous utilisons un service ClusterIP pour exposer l'application au cluster. Pour cela, nous allons utiliser le fichier YAML suivant:

```yaml
cat <<EOF > kubernetes/stateful-flask-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: stateful-flask
  namespace: stateful-flask
spec:
  selector:
    app: stateful-flask
  ports:
  - name: http
    protocol: TCP
    port: 5000
    targetPort: 5000
EOF
```

Appliquez le service:

```bash
kubectl apply -f kubernetes/stateful-flask-service.yaml
```

### Création d'un service externe pour notre application

Comme l'application est dans un namespace différent, nous devons créer un service externe pour exposer l'application au cluster. Pour ce faire, nous utiliserons le fichier YAML suivant:

```yaml
cat <<EOF > kubernetes/stateful-flask-service-externalname.yaml
apiVersion: v1
kind: Service
metadata:
  name: stateful-flask-service-externalname
  namespace: default
spec:
  type: ExternalName
  externalName: stateful-flask.stateful-flask.svc.cluster.local
EOF
```

Appliquez le service:

```bash
kubectl apply -f kubernetes/stateful-flask-service-externalname.yaml
```

### Configuration de l'ingress

Nous allons utiliser le fichier YAML suivant:

```bash
export ingress_ip=$(kubectl get services nginx-ingress-ingress-nginx-controller | awk '{print $4}' | tail -n 1)
```

```yaml
cat <<EOF > kubernetes/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-ingress
spec:
  rules:
  - host: stateful-flask.${ingress_ip}.nip.io
    http:
      paths:
      - path: /tasks
        pathType: Prefix
        backend:
          service:
            name: stateful-flask-service-externalname
            port:
              number: 5000
  ingressClassName: nginx
EOF
```

Assurez-vous de remplacer `<ip>` par l'adresse IP du controleur de l'ingress.

Appliquer l'ingress:

```bash
kubectl apply -f kubernetes/ingress.yaml
```

## Vérification des logs et vérification que tout fonctionne

Pour observer les logs d'application, nous pouvons utiliser la commande `kubectl logs`. Par exemple, nous pouvons exécuter la commande suivante pour afficher les logs du Pod `hello-world`:

```bash
kubectl logs hello-world
```

Si le Pod est dans un autre namespace, nous pouvons spécifier le namespace avec le drapeau `-n`:

```bash
kubectl logs hello-world -n my-namespace
```

Pour appliquer ceci à l'application `stateful-flask`, nous pouvons exécuter:

```bash
kubectl -n stateful-flask logs <NOM_DU_POD>
```

Vous devrez remplacer `<NOM_DU_POD>` par le nom du Pod que vous voulez voir les logs. Alternativement, vous pouvez obtenir le nom du Pod à partir du déploiement et l'utiliser dans la commande:

```bash
export pod=$(kubectl -n stateful-flask get pods -l app=stateful-flask -o jsonpath='{.items[0].metadata.name}')
kubectl -n stateful-flask logs $pod
```

Cependant, si vous disposez de plusieurs pods et souhaitez afficher les logs de tous, vous pouvez utiliser l'option `-l` pour spécifier le label de sélection :

```bash
kubectl -n stateful-flask  logs -l app=stateful-flask
```

Vous pouvez également utiliser l'option `-f` pour suivre les logs :

```bash
kubectl -n stateful-flask  logs -f -l app=stateful-flask
```

Ensuite, vous pouvez accéder à `http://stateful-flask.<ip>.nip.io/tasks` pour voir l'application en action.

Pour effectuer une requête POST à l'application et ajouter une tâche, vous pouvez utiliser `curl` (ou Postman). Par exemple, pour ajouter une tâche avec le titre "Ma première tâche" et la description "Ceci est ma première tâche", vous pouvez exécuter :

```bash
curl -X POST -H "Content-Type: application/json" -d '{"title":"Ma première tâche", "description":"Il s'agit de ma première tâche"}' "http://stateful-flask.<ip>.nip.io/tasks"
```

Assurez-vous de remplacer `http://stateful-flask.<ip>.nip.io` avec l'URL de votre application, que vous pouvez trouver dans la sortie de la commande `kubectl get ingress` ou en exécutant la commande suivante:

```bash
kubectl get ingress | awk '{print $3}' | tail -n 1
```

Vous pouvez également regrouper les deux commandes en une seule commande :

```bash
curl -X POST -H "Content-Type: application/json" -d "{\"title\":\"Ma première tâche\", \"description\":\"Il s'agit de ma première tâche\"}" "http://$(kubectl get ingress | awk '{print $3}' | tail -n 1)/tasks"
```

Maintenant, vous pouvez effectuer une requête GET à l'application pour voir les tâches que vous avez ajoutées :

```bash
curl "http://$(kubectl get ingress | awk '{print $3}' | tail -n 1)/tasks"
```

Si nous supprimons tous les pods de l'application et tous les pods de la base de données, nous ne perdrons pas les données car les données sont stockées dans le `PersistentVolumeClaim`.

Pour supprimer tous les pods de l'application, nous pouvons exécuter:

```bash
kubectl delete -f kubernetes/deployment.yaml
kubectl delete -f kubernetes/postgres-deployment.yaml
```

Redéployez l'application :

```bash
kubectl apply -f kubernetes/deployment.yaml
kubectl apply -f kubernetes/postgres-deployment.yaml
```

Maintenant, si nous effectuons une demande GET à l'application, nous verrons les tâches que nous avons ajoutées auparavant :

```bash
curl "http://$(kubectl get ingress | awk '{print $3}' | tail -n 1)/tasks"
```

## Résumé

Même si l'application Flask ne stocke pas son état en interne (stateless), elle stocke l'état de l'ensemble de l'application dans la base de données. Nous devons donc nous assurer que la base de données est persistante.

Dans cette partie du guide, nous avons vu comment déployer une base de données persistante sur Kubernetes utilisée par un microservice Flask Stateless. Nous avons également vu comment utiliser `PersistentVolumeClaim` pour stocker l'état de l'application dans un `PersistentVolume`. Même si l'exemple semble simple, c'est un bon point de départ pour comprendre comment combiner des microservices ayant des états différents sur Kubernetes.
